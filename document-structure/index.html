<!DOCTYPE html><html><head><meta charset="utf-8"/><meta http-equiv="X-UA-Compatible" content="IE=edge"/><title>Enriching Dutch Case Law Markup</title><meta name="description"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="apple-touch-icon" href="apple-touch-icon.png"/><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.6.0/katex.min.css"/><link rel="stylesheet" href="../style.css"/></head><body class="p2"><header class="py2"><h1 class="mt0">Enriching Dutch Case Law Markup</h1></header><section><ol class="mxn2"><li><a href="../introduction/" class="nav-link">Introduction</a><ol><li>Rechtspraak.nl</li><li>Rechtspraak.nl markup</li><li>Importing &amp; Tokenizing Data</li></ol></li><li><a href="../tagging/" class="nav-link">Tagging Elements</a><ol><li>Feature Selection</li><li>Conditional Random Fields</li><li>Deterministic Tagger</li><li>Evaluation</li></ol></li><li><span>Inferring a Document Structure</span></li></ol><h2>Inferring a Document Structure</h2><section id="introduction"><h3>Introduction</h3><div><p>After we have labeled our sequence of text elements, we wish to infer some sort of document structure. We approach this problem as parsing a sequence of terminals with a Stochastic Context Free Grammar (SCFG) into an abstract parse tree, represent the document section hierarchy.</p><p>In this chapter, we introduce SCFGs and the Cocke–Younger–Kasami algorithm (CYK), a deterministic algorithm for finding the best parse tree in quadratic space and time. We conclude with an evaluation of the results.</p></div></section><section id="scfg"><h3>Stochastic Context Free Grammars</h3><div><section><h3>Stochastic Context Free Grammars</h3><p>Context Free Grammars (CFGs) are grammars</p></section></div></section><section id="cyk"><h3>CYK Algorithm</h3><div><p>The Cocke–Younger–Kasami (CYK) algorithm is an algorithm for parsing Context Free Grammars that was separately discovered by <a class="inline-citation" href="#kasami1965efficient">Kasami (1965)</a>, <a class="inline-citation" href="#younger1967recognition">Younger (1967, pp. 189—208)</a> and <a class="inline-citation" href="#cocke1969programming">Cocke (1969)</a>. The algorithm has worst case complexity of <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">Θ</mi><mo>(</mo><msup><mi>n</mi><mn>3</mn></msup><mo>⋅</mo><mrow><mo fence="true">∣</mo><mi>G</mi><mo fence="true">∣</mo></mrow><mo>)</mo></mrow><annotation encoding="application/x-tex">\Theta (n^3\cdot \left | G \right |)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8141079999999999em;"></span><span class="strut bottom" style="height:1.064108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">Θ</span><span class="mopen">(</span><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">3</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">⋅</span><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">∣</span><span class="mord mathit">G</span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">∣</span></span><span class="mclose">)</span></span></span></span></span>, where <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span></span></span></span></span> is the length of the input string and <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">∣</mo><mi>G</mi><mo fence="true">∣</mo></mrow></mrow><annotation encoding="application/x-tex">\left | G \right |</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">∣</span><span class="mord mathit">G</span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">∣</span></span></span></span></span></span> is the size of the grammar.</p><p>The standard version of the CYK algorithm is defined for ordinary context free grammars that are given in Chomsky normal form (CNF), but is is easy to extend the algorithm to work on stochastic grammars with unary rules, as we do in this section. Note that any CFG may be transformed into an equivalent grammar in Chomsky normal form, and this also holds for stochastic CFGs (<a class="inline-citation" href="#huang1971stochastic"> (1971, pp. 201—224)</a>). Also note that converting a grammar to CNF is not without cost: the increase in grammar size is <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">O</mi><mo>(</mo><msup><mrow><mo fence="true">∣</mo><mi>G</mi><mo fence="true">∣</mo></mrow><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathrm O (\left | G \right |^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8151079999999999em;"></span><span class="strut bottom" style="height:1.065108em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">O</span><span class="mopen">(</span><span class="minner"><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">∣</span><span class="mord mathit">G</span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;">∣</span></span><span class="vlist"><span style="top:-0.364em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mclose">)</span></span></span></span></span> for the best algorithm, but the increase is linear if we use a variation of the algorithm that works on grammars in binary normal form (2NF). (<a class="inline-citation" href="#lange2009cnf">Lange and Leiß (2009, pp. 2008—2010)</a>.)</p><p>The algorithm is a bottom-up parsing algorithm. The algorith considers every substring from length <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span></span></span></span></span> to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.43056em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathit">n</span></span></span></span></span>, and tries to assign a non-terminal label to the substring along with a score. For substrings of length <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span></span></span></span></span> (individual words), we use the terminal rules in the grammar. For substrings of length <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l&gt;1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.73354em;vertical-align:-0.0391em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mrel">&gt;</span><span class="mord mathrm">1</span></span></span></span></span> (word sequences), we apply the production rules to every possible combination of two substrings of length <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>l</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">l-1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.01968em;">l</span><span class="mbin">−</span><span class="mord mathrm">1</span></span></span></span></span> (remember that CNF mandates that all production rules have 2 non-terminals). Every time we apply a rule, we multiply the probability attached to the rule and the probabilities of the constituent substrings.</p><p>This describes the basic version of CYK. In addition to this, we also allow unary rules in our grammar of the form <code>A → B</code>, where <code>A</code> and <code>B</code> are nonterminals. Extension of the algorith is simple: at the end of every substring assignment, we apply unary rules, and add the result if the rule produces a non-terminal that does not exist with at least that score in the table. We repeat until the cell does not change anymore.</p><p>A visual example of the result table can be found in <a href="#fig-parsing-triangle">Figure 1</a>.</p><figure id="fig-parsing-triangle"><div class="table-container"><table><tbody><tr><td><div class="cyk-cell-content"><ol><li><code>N (20%)</code></li><li><code>V (60%)</code></li><li><code><strong>NP (14%)</strong></code></li><li><code>VP (6%)</code></li><li><code>S (0.6%)</code></li></ol><code class="word">fish</code></div></td><td><div class="cyk-cell-content"><ol><li><code><strong>NP (0.49%)</strong></code></li><li><code>VP (10.5%)</code></li><li><code>S (1.05%)</code></li></ol></div></td><td><div class="cyk-cell-content"><ol><li><code>NP (0.0069%)</code></li><li><code>VP (0.147%)</code></li><li><code>S (0.09%)</code></li></ol></div></td><td><div class="cyk-cell-content"><ol><li><code>VP (0.002%)</code></li><li><code>NP (0.00001%)</code></li><li><code><strong>S (0.019%)</strong></code></li></ol></div></td></tr><tr><td></td><td><div class="cyk-cell-content"><ol><li><code>N (50%)</code></li><li><code>V (10%)</code></li><li><code><strong>NP (35%)</strong></code></li><li><code>VP (1%)</code></li><li><code>S (0.1%)</code></li></ol><code class="word">people</code></div></td><td><div class="cyk-cell-content"><ol><li><code>NP (0.49%)</code></li><li><code>VP (0.7%)</code></li><li><code>S (1.89%)</code></li></ol></div></td><td><div class="cyk-cell-content"><ol><li><code>NP (0.007%)</code></li><li><code>VP (0.010%)</code></li><li><code>S (1.323%)</code></li></ol></div></td></tr><tr><td></td><td></td><td><div class="cyk-cell-content"><ol><li><code>N (20%)</code></li><li><code><strong>V (60%)</strong></code></li><li><code>NP (14%)</code></li><li><code>VP (6%)</code></li><li><code>S (0.6%)</code></li></ol><code class="word">fish</code></div></td><td><div class="cyk-cell-content"><ol><li><code>NP (0.196%)</code></li><li><code><strong>VP (4.2%)</strong></code></li><li><code>S (0.42%)</code></li></ol></div></td></tr><tr><td></td><td></td><td></td><td><div class="cyk-cell-content"><ol><li><code>N (20%)</code></li><li><code>V (30%)</code></li><li><code><strong>NP (14%)</strong></code></li><li><code>VP (3%)</code></li><li><code>S (0.3%)</code></li></ol><code class="word">tanks</code></div></td></tr></tbody></table></div><figcaption><span class="figure-number">Fig 1.</span> An example parse chart for the sentence &quot;fish people fish tanks&quot;, with the following grammar:<div><pre style="display:inline-block;">S  → NP VP  (90%)<br/>S  → VP     (10%)<br/>VP → V NP   (50%)<br/>VP → V      (10%)<br/>NP → NP NP  (10%)<br/>NP → N      (70%)<br/><br/>N  → fish   (20%)<br/>N  → people (50%)<br/>N  → tanks  (20%)<br/>V  → people (10%)<br/>V  → fish   (60%)<br/>V  → tanks  (30%)</pre></div>The top of the triangle represents the substring <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span></span></span></span></span> to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">4</span></span></span></span></span>, i.e. the entire sentence. We can derive <code>S</code> by combining the substring from <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">1</span></span></span></span></span> to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">2</span></span></span></span></span> (<code>fish people</code>) and the substring from <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">3</span></span></span></span></span> to <span><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.64444em;"></span><span class="strut bottom" style="height:0.64444em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord mathrm">4</span></span></span></span></span> (<code>fish tanks</code>) using the rule <code>S → NP VP</code>. The nodes that make up a parse tree to <code>S</code> are marked.</figcaption></figure><p>The implementation of this algorithm can be found on Github.</p></div></section><section id="evaluation"><h3>Evaluation</h3><div><p>- minimal edit distance? -</p></div></section></section><section id="bibliography"><h2>References</h2><ol id="reference-list"><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="jordan2002discriminative" class="ref"><span class="ref-author">Ng, Andrew and Jordan, Michael</span> (<time datetime="2002" class="ref-year">2002</time>). <cite><a><span itemprop="name">On discriminative vs. generative classifiers: A comparison of logistic regression and naive bayes</span></a></cite>. <span><span class="ref-journal">Advances in neural information processing systems</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="younger1967recognition" class="ref"><span class="ref-author">Younger, Daniel</span> (<time datetime="1967" class="ref-year">1967</time>). <cite><a><span itemprop="name">Recognition and parsing of context-free languages in time n³</span></a></cite>. <span><span class="ref-journal">Information and control</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="kasami1965efficient" class="ref"><span class="ref-author">Kasami, Tadao</span> (<time datetime="1965" class="ref-year">1965</time>). <cite><a><span itemprop="name">AN EFFICIENT RECOGNITION AND SYNTAX ANALYSIS ALGORITHM FOR CONTEXT-FREE LANGUAGES</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="sipser2006introduction" class="ref"><span class="ref-author">Sipser, Michael</span> (<time datetime="2006" class="ref-year">2006</time>). <cite><a><span itemprop="name">Introduction to the Theory of Computation</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="huang1971stochastic" class="ref"><span class="ref-author">undefined</span> (<time datetime="1971" class="ref-year">1971</time>). <cite><a><span itemprop="name">On stochastic context-free languages</span></a></cite>. <span><span class="ref-journal">Information Sciences</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="lange2009cnf" class="ref"><span class="ref-author">Lange, Martin and Leiß, Hans</span> (<time datetime="2009" class="ref-year">2009</time>). <cite><a><span itemprop="name">To CNF or not to CNF? An efficient yet presentable version of the CYK algorithm</span></a></cite>. <span><span class="ref-journal">Informatica Didactica</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="cocke1969programming" class="ref"><span class="ref-author">Cocke, John</span> (<time datetime="1969" class="ref-year">1969</time>). <cite><a><span itemprop="name">Programming languages and their compilers: Preliminary notes</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="vanopijnen2014" class="ref"><span class="ref-author">van Opijnen, Marc</span> (<time datetime="2014" class="ref-year">2014</time>). <cite><a href="http://dare.uva.nl/record/1/408882"><span itemprop="name">Op en in het web: Hoe de toegankelijkheid van rechterlijke uitspraken kan worden verbeterd</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="trompper2014" class="ref"><span class="ref-author">Trompper</span> (<time datetime="2014" class="ref-year">2014</time>). <cite><a href="http://leibniz-internship-report.herokuapp.com/eu-legal-data-survey/nl#rechtspraak.nl"><span itemprop="name">NL open legal data survey: Rechtspraak.nl</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="mccallum2000maximum" class="ref"><span class="ref-author">McCallum, Andrew and Freitag, Dayne and Pereira, Fernando</span> (<time datetime="2000" class="ref-year">2000</time>). <cite><a href="http://cseweb.ucsd.edu/~elkan/254spring02/gidofalvi.pdf"><span itemprop="name">Maximum Entropy Markov Models for Information Extraction and Segmentation</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="mallet" class="ref"><span class="ref-author">McCallum, Andrew Kachites</span> (<time datetime="2002" class="ref-year">2002</time>). <cite><a href="http://mallet.cs.umass.edu"><span itemprop="name">MALLET: A Machine Learning for Language Toolkit</span></a></cite>. </li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="sutton2006introduction" class="ref"><span class="ref-author">Sutton, Charles and McCallum, Andrew</span> (<time datetime="2006" class="ref-year">2006</time>). <cite><a><span itemprop="name">An introduction to conditional random fields for relational learning</span></a></cite>. <span><span class="ref-journal">Introduction to statistical relational learning</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="finkel2004exploiting" class="ref"><span class="ref-author">Finkel, Jenny and Dingare, Shipra and Nguyen, Huy and Nissim, Malvina and Manning, Christopher and Sinclair, Gail</span> (<time datetime="2004" class="ref-year">2004</time>). <cite><a><span itemprop="name">Exploiting context for biomedical entity recognition: from syntax to the web</span></a></cite>. <span><span class="ref-journal">Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="klinger2009feature" class="ref"><span class="ref-author">Klinger, Roman and Friedrich, Christoph</span> (<time datetime="2009" class="ref-year">2009</time>). <cite><a><span itemprop="name">Feature Subset Selection in Conditional Random Fields for Named Entity Recognition</span></a></cite>. <span><span class="ref-journal">RANLP</span>.</span></li><li itemprop="citation" itemscope="" itemtype="http://schema.org/CreativeWork" id="krishnan2006effective" class="ref"><span class="ref-author">Krishnan, Vijay and Manning, Christopher D</span> (<time datetime="2006" class="ref-year">2006</time>). <cite><a><span itemprop="name">An effective two-stage model for exploiting non-local dependencies in named entity recognition</span></a></cite>. <span><span class="ref-journal">Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics</span>.</span></li></ol></section><script id="initial-props" type="application/json">{"path":"/document-structure/","assets":{"css":"bundle.js","main":"bundle.js"},"title":"Enriching Dutch Case Law Markup","routes":["/","/introduction/","/tagging/","/document-structure/"]}</script><script src="../bundle.js"></script><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='https://www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create','','auto');</script></body></html>